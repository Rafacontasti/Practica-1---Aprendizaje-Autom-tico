{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**<h1>Implementación del modelo final</h1>**"
      ],
      "metadata": {
        "id": "9eRglWFKD7Pq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JxuoHXKy4TZO",
        "outputId": "aa64ff97-7597-4c7c-903f-8211657b242d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n"
          ]
        }
      ],
      "source": [
        "# Importamos las librerías correspondientes\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Cargar los datos en un DataFrame\n",
        "comp_df = pd.read_csv(\"/comp_st23ns1.txt.bz2\", compression=\"bz2\", index_col=0)\n",
        "disp_df = pd.read_csv(\"/disp_st23ns1.txt.bz2\", compression=\"bz2\",index_col=0)\n",
        "\n",
        "# Dividir los datos en 10 años para entrenamiento\n",
        "numero_filas_train = 365 * 10\n",
        "train = disp_df.iloc[:numero_filas_train, :]\n",
        "\n",
        "# Las pruebas se hacen en los datos de competición\n",
        "test = comp_df.iloc[:]\n",
        "\n",
        "# Dividir los datos de entrenamiento en las variables (X) y la salida (y)\n",
        "# Todas las columnas excepto la última\n",
        "X_train = train.iloc[:, :-1]\n",
        "# Última columna\n",
        "y_train = train.iloc[:, -1]\n",
        "# Todas las columnas ya que los datos de competición no tienen salida\n",
        "X_test = test\n",
        "\n",
        "scaler = StandardScaler()\n",
        "svr = SVR()\n",
        "\n",
        "pipe_regr = Pipeline([\n",
        "    ('scale', scaler),\n",
        "    ('SVM', svr)])\n",
        "\n",
        "# Definición del espacio de búsqueda de hiperparámetros\n",
        "param_grid = {'SVM__C': [0.1, 1, 10, 100, 1000, 10000, 100000, 1000000,10000000, 100000000],\n",
        "              'SVM__gamma': [0.01, 0.1, 1]}\n",
        "\n",
        "inner = KFold(n_splits=3, shuffle=True, random_state=42)\n",
        "\n",
        "# Definición de un proceso de 2 pasos que ajusta automáticamente 2 hiperparámetros\n",
        "modelo_final = GridSearchCV(pipe_regr, \n",
        "                        param_grid,\n",
        "                        scoring='neg_mean_squared_error',\n",
        "                        cv=inner, \n",
        "                        n_jobs=4, verbose=1)\n",
        "\n",
        "# Se entrena el proceso de ajuste automático\n",
        "np.random.seed(42)\n",
        "modelo_final.fit(X=X_train, y=y_train.values.ravel())\n",
        "\n",
        "# 'modelo_final' contiene el modelo con los mejores hiperparámetros encontrados por gridsearch\n",
        "# y entrenado en el conjunto completo de 'X_train'\n",
        "\n",
        "# Guardamos el modelo final en un archivo pickle\n",
        "with open('modelo_final.pkl', 'wb') as file:\n",
        "    pickle.dump(modelo_final, file)\n",
        "\n",
        "# Cargamos el modelo desde el archivo pickle\n",
        "with open('modelo_final.pkl', 'rb') as file:\n",
        "    modelo_final = pickle.load(file)\n",
        "\n",
        "# Se obtienen las predicciones para el conjunto de prueba\n",
        "y_pred = modelo_final.predict(X_test)\n",
        "\n",
        "# Finalmente, se guardan las predicciones en un archivo CSV\n",
        "predicciones_df = pd.DataFrame({'Predicciones': y_pred})\n",
        "predicciones_df.to_csv('predicciones.csv', index=False)"
      ]
    }
  ]
}